{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCRIM - per capita crime rate by town\\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\\nINDUS - proportion of non-retail business acres per town.\\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\\nNOX - nitric oxides concentration (parts per 10 million)\\nRM - average number of rooms per dwelling\\nAGE - proportion of owner-occupied units built prior to 1940\\nDIS - weighted distances to five Boston employment centres\\nRAD - index of accessibility to radial highways\\nTAX - full-value property-tax rate per $10,000\\nPTRATIO - pupil-teacher ratio by town\\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\nLSTAT - % lower status of the population\\nMEDV - Median value of owner-occupied homes in $1000's\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CRIM - per capita crime rate by town\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "RM - average number of rooms per dwelling\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "RAD - index of accessibility to radial highways\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "LSTAT - % lower status of the population\n",
    "MEDV - Median value of owner-occupied homes in $1000's\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data\n",
    "\n",
    "data.keys()\n",
    "\n",
    "\n",
    "data_target = data['MEDV']\n",
    "data = data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
    "       'PTRATIO', 'B', 'LSTAT']]\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test.shape:  (102,) \n",
      "y_test: 173    23.6\n",
      "274    32.4\n",
      "491    13.6\n",
      "72     22.8\n",
      "452    16.1\n",
      "       ... \n",
      "412    17.9\n",
      "436     9.6\n",
      "411    17.2\n",
      "86     22.5\n",
      "75     21.4\n",
      "Name: MEDV, Length: 102, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data_target, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#print(\"X_train.shape: \", X_train.shape, \"\\nX_train:\", X_train)\n",
    "#print(\"X_test.shape: \", X_test.shape, \"\\nX_test:\", X_test)\n",
    "#print(\"y_train.shape: \", y_train.shape, \"\\ny_train:\", y_train)\n",
    "#print(\"y_test.shape: \", y_test.shape, \"\\ny_test:\", y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_pred:  [10.96952405 19.41196567 23.06419602 12.1470648  18.3738116  25.24677946\n",
      " 20.77024774 23.90932632  7.81713319 19.60988098 21.8202963  27.59615864\n",
      " 32.67986504 15.12308446 35.3964561  12.99688651 20.728181   28.30223542\n",
      " 15.61724836 24.45143096  4.61794591 23.76681932 25.56178249 22.98928526\n",
      " 24.5213025  34.06407919 19.71166707 39.11233072 14.62515846 24.81139885\n",
      " 18.02332883 20.85836445  9.57577261 20.87246835 22.28583096 31.79327155\n",
      " 31.04748307 15.70611763 17.01382935 28.23332703 24.27661276 16.88670215\n",
      "  6.90720745 26.75808901 22.586493   17.53664716 13.77197016 41.04840929\n",
      " 16.44690754 18.23531669 25.37038646 23.64581399 22.05322581 20.83620499\n",
      " 16.93508273 22.797579   29.13333934  7.69310515 24.60571452 17.2358028\n",
      " 21.10846551 25.15150324 27.33394823 21.30494963 41.5811902  19.19666651\n",
      " 15.37955448 19.33545877 17.04687638 22.96801532 23.11094953 33.6977586\n",
      " 22.77436405 20.28968381 25.35517813 31.02479125 33.05103792 28.44712333\n",
      "  8.50926331  5.61220643 12.81228164 19.81854491 34.8603548  33.47481463\n",
      " 15.81288676  4.16863764 32.81131556 21.22307142 18.97752706 26.36174269\n",
      " 18.38053781 17.80316891 11.8730344  31.84801205 24.45344478 20.0222241\n",
      " 19.5225374  11.8723419  28.90289906 19.7133604  32.47093634 33.20696505\n",
      " 24.79405395 21.25197228 25.03045081 43.36995367 29.54151469 33.75302939\n",
      " 26.27516427 27.04791799 15.1908027  31.34177077 20.85218327 31.05070715\n",
      " 28.74449991 21.16535503 23.06717742 12.48881717 36.48751917 37.24291141\n",
      " 33.23617345  5.30863493 20.82773333 22.16769067 35.62579793 17.10890633\n",
      " 22.76667    19.50567599 26.36980524 16.03780391 20.63186041 27.04508116\n",
      " 31.39596353 31.12597743 22.78355908 39.11521781 28.28378993 30.53090392\n",
      " 28.89518723 21.08389783 29.04801464 16.151087   22.08243372 24.61505524\n",
      " 18.95878457  2.06366066 20.51120467 26.85927261 23.0775764  18.40141847\n",
      " 22.70378324 15.95162657 31.54559763 27.82356386 34.19210038 20.70876151\n",
      " 15.1538496  19.55740929  8.31853813 13.62525632 26.48611752 16.52769982\n",
      "  4.13593772 24.73356662 12.21856959 28.24704463 33.60549853 36.84177072\n",
      " 24.28136146 20.7199677  30.79885576 36.93823489 19.92152434 19.59433404\n",
      " 28.76197718 13.28347615 13.41116334 10.89910148 19.07573086 22.65911351\n",
      " 30.27080271 29.77482371 17.89252221 29.83838757 14.41987694 13.24056207\n",
      " 33.87859379 19.6406762  14.54072369 23.66498192 22.41851151 19.63248447\n",
      " 24.660086   35.00833944  4.12171868 20.79593953 33.240402   18.04778742\n",
      " 22.6208596  22.39592759 21.4012853  11.74782838 38.18786922 25.76751814\n",
      " 24.80115706 16.36524419 31.98045427 36.35420843 39.11016375 20.33864814\n",
      " 22.16464728 16.34276966 39.35137104  6.74954317 21.35789894 15.53370378\n",
      " 26.91527204  8.80382559 20.93301971 -0.20588155 17.21501492 16.17150935\n",
      "  8.48374754 23.08202496 17.23085262 29.42673011 44.36436789 28.09470335\n",
      " 23.75911874 36.75959172  8.71594791 25.90885934 20.83832124 23.68119542\n",
      " 19.85753143 22.2992237  14.72942336 18.4266911  22.45346464 23.75648384\n",
      " 28.82492146 23.58310886 27.30142666 18.06532614 13.16799771 31.66795775\n",
      " 28.77291955 12.60179253 17.38668341 24.05174693 40.7163898  23.0214736\n",
      " 12.83596226 28.55024128 36.850343   23.26391794 25.14113573 38.36624745\n",
      " 18.21318365 25.69614391 15.22833068 24.14345412 36.27095489 31.03140871\n",
      " 24.82017075 17.7834844  17.99307546  8.61827851 41.51965821 19.63259696\n",
      " 30.16241039 19.69581658 14.59963591 20.29467675 24.22053288 34.79282666\n",
      " 26.51552807 41.665796   12.32829593 14.32092274 23.69090327 18.01762114\n",
      " 19.72399411 29.13009315 11.10216617 24.11213143 18.54668994 23.69765843\n",
      " 30.11853879 19.34756033 12.52355093 33.74737806 16.90295464 17.83165159\n",
      " 19.34064029 26.74379491 35.24575625 12.92253178 26.69073573 19.19640769\n",
      " 30.29549933 17.83878909 22.92058129 29.13254708 20.02093559 25.18893157\n",
      " 20.95650827 20.57624549 32.93168351 20.43565472 25.41798459 28.14952635\n",
      " 37.59066882 25.0548289  28.61534646 17.97695227 30.78085325 23.57491321\n",
      " 34.56676284 18.52592551 23.86972656 13.82862001 25.18152388 17.67219765\n",
      " 12.63704156 17.03927502 14.2510159  28.56862619 22.99037971 13.42262376\n",
      " 17.40965124 34.44268371 12.93938984 14.62427657 27.50209814 21.28772373\n",
      " 21.8475453  27.75030943 16.84106111 35.70395065 23.19717187 19.70894368\n",
      " 20.39856551 31.03155183  5.16165827 36.26386827 38.27409562 21.44507004\n",
      " 21.53203698 13.25546637 35.43733953 19.75468373 21.59325014 27.28654912\n",
      " 14.70336355 20.10948908 20.98738625 20.42268561 26.20840113 11.28815662\n",
      " 34.57059129 22.65270668 22.68814063 33.20155069 26.77878535 21.55230365\n",
      "  8.80963918 28.40878163 25.10012639 25.47646583 17.70215249 25.63601841\n",
      " 18.61140436 32.77937269 35.77461311 18.3180684  30.14080347  7.72488159\n",
      " 26.25987699 10.52826879 27.30604251 44.10078731 28.92351314 14.7836951\n",
      " 20.79445301 17.96782515 19.333174   33.02714571 25.71055958 25.89232968\n",
      " 17.07165041 21.95432205 11.3511532  13.27742402 22.66485295 22.52252947\n",
      " 12.30424735 32.08396429 22.11175771 17.24071878 22.00480027 26.7237425\n",
      " 12.97674212 19.14279551]\n",
      "\n",
      "y_test_pred:  [28.99672362 36.02556534 14.81694405 25.03197915 18.76987992 23.25442929\n",
      " 17.66253818 14.34119    23.01320703 20.63245597 24.90850512 18.63883645\n",
      " -6.08842184 21.75834668 19.23922576 26.19319733 20.64773313  5.79472718\n",
      " 40.50033966 17.61289074 27.24909479 30.06625441 11.34179277 24.16077616\n",
      " 17.86058499 15.83609765 22.78148106 14.57704449 22.43626052 19.19631835\n",
      " 22.43383455 25.21979081 25.93909562 17.70162434 16.76911711 16.95125411\n",
      " 31.23340153 20.13246729 23.76579011 24.6322925  13.94204955 32.25576301\n",
      " 42.67251161 17.32745046 27.27618614 16.99310991 14.07009109 25.90341861\n",
      " 20.29485982 29.95339638 21.28860173 34.34451856 16.04739105 26.22562412\n",
      " 39.53939798 22.57950697 18.84531367 32.72531661 25.0673037  12.88628956\n",
      " 22.68221908 30.48287757 31.52626806 15.90148607 20.22094826 16.71089812\n",
      " 20.52384893 25.96356264 30.61607978 11.59783023 20.51232627 27.48111878\n",
      " 11.01962332 15.68096344 23.79316251  6.19929359 21.6039073  41.41377225\n",
      " 18.76548695  8.87931901 20.83076916 13.25620627 20.73963699  9.36482222\n",
      " 23.22444271 31.9155003  19.10228271 25.51579303 29.04256769 20.14358566\n",
      " 25.5859787   5.70159447 20.09474756 14.95069156 12.50395648 20.72635294\n",
      " 24.73957161 -0.164237   13.68486682 16.18359697 22.27621999 24.47902364]\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "data_LR = LinearRegression()\n",
    "\n",
    "data_LR.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = data_LR.predict(X_train)\n",
    "y_test_pred  = data_LR.predict(X_test)\n",
    "\n",
    "print(\"y_train_pred: \", y_train_pred)\n",
    "print(\"\\ny_test_pred: \", y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_squared_score_train:  0.7508856358979673\n",
      "r_squared_score_test:  0.6687594935356307\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared_score_train = r2_score(y_train, y_train_pred)\n",
    "r_squared_score_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"r_squared_score_train: \", r_squared_score_train)\n",
    "print(\"r_squared_score_test: \", r_squared_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error, Train: 21.641412753226312\n",
      "Mean squared error, Test:  24.291119474973613\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f\"Mean squared error, Train: {mean_squared_error(y_train, y_train_pred)}\")\n",
    "print(f\"Mean squared error, Test:  {mean_squared_error(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_absolute_error, Train: 3.314771626783227\n",
      "Mean_absolute_error, Test:  3.189091965887852\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(f\"Mean_absolute_error, Train: {mean_absolute_error(y_train, y_train_pred)}\")\n",
    "print(f\"Mean_absolute_error, Test:  {mean_absolute_error(y_test, y_test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 150 (50 in each of three classes)\n",
      ":Number of Attributes: 4 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - sepal length in cm\n",
      "    - sepal width in cm\n",
      "    - petal length in cm\n",
      "    - petal width in cm\n",
      "    - class:\n",
      "            - Iris-Setosa\n",
      "            - Iris-Versicolour\n",
      "            - Iris-Virginica\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============== ==== ==== ======= ===== ====================\n",
      "                Min  Max   Mean    SD   Class Correlation\n",
      "============== ==== ==== ======= ===== ====================\n",
      "sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "============== ==== ==== ======= ===== ====================\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: 33.3% for each of 3 classes.\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. dropdown:: References\n",
      "\n",
      "  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "    Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "    Structure and Classification Rule for Recognition in Partially Exposed\n",
      "    Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "    Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "    on Information Theory, May 1972, 431-433.\n",
      "  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "    conceptual clustering system finds 3 classes in the data.\n",
      "  - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "column_names = data.feature_names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'], columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "145  2\n",
       "146  2\n",
       "147  2\n",
       "148  2\n",
       "149  2\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = pd.DataFrame(data.target)\n",
    "display(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (120, 4) \n",
      "X_train:      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "22                 4.6               3.6                1.0               0.2\n",
      "15                 5.7               4.4                1.5               0.4\n",
      "65                 6.7               3.1                4.4               1.4\n",
      "11                 4.8               3.4                1.6               0.2\n",
      "42                 4.4               3.2                1.3               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "71                 6.1               2.8                4.0               1.3\n",
      "106                4.9               2.5                4.5               1.7\n",
      "14                 5.8               4.0                1.2               0.2\n",
      "92                 5.8               2.6                4.0               1.2\n",
      "102                7.1               3.0                5.9               2.1\n",
      "\n",
      "[120 rows x 4 columns]\n",
      "\n",
      "X_test.shape:  (30, 4) \n",
      "X_test:      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "73                 6.1               2.8                4.7               1.2\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "118                7.7               2.6                6.9               2.3\n",
      "78                 6.0               2.9                4.5               1.5\n",
      "76                 6.8               2.8                4.8               1.4\n",
      "31                 5.4               3.4                1.5               0.4\n",
      "64                 5.6               2.9                3.6               1.3\n",
      "141                6.9               3.1                5.1               2.3\n",
      "68                 6.2               2.2                4.5               1.5\n",
      "82                 5.8               2.7                3.9               1.2\n",
      "110                6.5               3.2                5.1               2.0\n",
      "12                 4.8               3.0                1.4               0.1\n",
      "36                 5.5               3.5                1.3               0.2\n",
      "9                  4.9               3.1                1.5               0.1\n",
      "19                 5.1               3.8                1.5               0.3\n",
      "56                 6.3               3.3                4.7               1.6\n",
      "104                6.5               3.0                5.8               2.2\n",
      "69                 5.6               2.5                3.9               1.1\n",
      "55                 5.7               2.8                4.5               1.3\n",
      "132                6.4               2.8                5.6               2.2\n",
      "29                 4.7               3.2                1.6               0.2\n",
      "127                6.1               3.0                4.9               1.8\n",
      "26                 5.0               3.4                1.6               0.4\n",
      "128                6.4               2.8                5.6               2.1\n",
      "131                7.9               3.8                6.4               2.0\n",
      "145                6.7               3.0                5.2               2.3\n",
      "108                6.7               2.5                5.8               1.8\n",
      "143                6.8               3.2                5.9               2.3\n",
      "45                 4.8               3.0                1.4               0.3\n",
      "30                 4.8               3.1                1.6               0.2\n",
      "\n",
      "y_train.shape:  (120, 1) \n",
      "y_train:      0\n",
      "22   0\n",
      "15   0\n",
      "65   1\n",
      "11   0\n",
      "42   0\n",
      "..  ..\n",
      "71   1\n",
      "106  2\n",
      "14   0\n",
      "92   1\n",
      "102  2\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "\n",
      "y_test.shape:  (30, 1) \n",
      "y_test:      0\n",
      "73   1\n",
      "18   0\n",
      "118  2\n",
      "78   1\n",
      "76   1\n",
      "31   0\n",
      "64   1\n",
      "141  2\n",
      "68   1\n",
      "82   1\n",
      "110  2\n",
      "12   0\n",
      "36   0\n",
      "9    0\n",
      "19   0\n",
      "56   1\n",
      "104  2\n",
      "69   1\n",
      "55   1\n",
      "132  2\n",
      "29   0\n",
      "127  2\n",
      "26   0\n",
      "128  2\n",
      "131  2\n",
      "145  2\n",
      "108  2\n",
      "143  2\n",
      "45   0\n",
      "30   0\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape, \"\\nX_train:\", X_train)\n",
    "print(\"\\nX_test.shape: \", X_test.shape, \"\\nX_test:\", X_test)\n",
    "print(\"\\ny_train.shape: \", y_train.shape, \"\\ny_train:\", y_train)\n",
    "print(\"\\ny_test.shape: \", y_test.shape, \"\\ny_test:\", y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_pred:  [0 0 2 0 0 2 2 0 0 0 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2 2 0 0 0 2 2 0 0 0 2 0 2\n",
      " 2 0 2 2 0 2 2 2 2 2 2 0 2 2 0 0 2 2 0 2 0 0 2 2 2 2 2 2 2 0 0 2 2 0 0 0 2\n",
      " 2 0 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 0 2 2 0 2 2 2 0 2 2 2 0 2 0 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 0 2 2]\n",
      "\n",
      "y_test_pred:  [2 0 2 2 2 0 2 2 2 2 2 0 0 0 0 2 2 2 2 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = LR.predict(X_train)\n",
    "y_test_pred  = LR.predict(X_test)\n",
    "\n",
    "print(\"y_train_pred: \", y_train_pred)\n",
    "print(\"\\ny_test_pred: \", y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  0.6583333333333333\n",
      "Test accuracy score:  0.7\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train accuracy score: \", accuracy_train) \n",
    "print(\"Test accuracy score: \", accuracy_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train balanced accuracy score:  0.6583333333333333\n",
      "Test balanced accuracy score:  0.7\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "balanced_accuracy_test  = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train balanced accuracy score: \", accuracy_train) \n",
    "print(\"Test balanced accuracy score: \", accuracy_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train precision score:  0.6583333333333333\n",
      "Test precision score:  0.7\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_train = precision_score(y_train, y_train_pred, average = 'micro')\n",
    "precision_test  = precision_score(y_test, y_test_pred, average = 'micro')\n",
    "\n",
    "print(\"Train precision score: \", precision_train) \n",
    "print(\"Test precision score: \", precision_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall score:  0.6583333333333333\n",
      "Test recall score:  0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nA high recall score indicates that the model is good at identifying all positive instances, \\nwhile a low score suggests that the model is missing many positive samples.\\n'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_train = recall_score(y_train, y_train_pred, average = 'micro')\n",
    "recall_test  = recall_score(y_test, y_test_pred, average = 'micro')\n",
    "\n",
    "print(\"Train recall score: \", recall_train) \n",
    "print(\"Test recall score: \", recall_test)\n",
    "\n",
    "'''\n",
    "A high recall score indicates that the model is good at identifying all positive instances, \n",
    "while a low score suggests that the model is missing many positive samples.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score:  0.6583333333333333\n",
      "Test f1 score:  0.7\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_train = f1_score(y_train, y_train_pred, average = 'micro')\n",
    "f1_test  = f1_score(y_test, y_test_pred, average = 'micro')\n",
    "\n",
    "print(\"Train f1 score: \", f1_train) \n",
    "print(\"Test f1 score: \", f1_test)\n",
    "\n",
    "'''\n",
    "F-measure or balanced F-score, is a metric used to evaluate the performance of a classification model. \n",
    "Is a harmonic mean of precision and recall, providing a balanced view of both metrics.\n",
    "\n",
    "Higher F1 scores indicate better performance: \n",
    "An F1 score closer to 1 represents excellent performance, while a score closer to 0 indicates poor performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0 10]]\n"
     ]
    }
   ],
   "source": [
    "# Your code here :\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize = False, title = 'Confusion matrix', cmap = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    \n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "print(confusion_matrix(y_test, y_test_pred, labels=[1,0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have fun here !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
